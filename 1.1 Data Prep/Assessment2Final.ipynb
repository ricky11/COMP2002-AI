{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1 - Machine Learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.1 - Data Preparation\n",
    "There are 100 rows and 11 dimensions in the dataset. The data is 100% dense. Feature labels were added.\n",
    "\n",
    "Task is to predict the number of containers a ship can carry. \n",
    "The target is known hence this is supervised learning.\n",
    "\n",
    "From the inputs we want to get a output of the weighted sum : ùë¶ = ùëì(ùë•ùë§)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import necessary modules and Read data,add feature names\n",
    "- Call the head method to get a general overview of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required modules\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "cols = [\"IMO_NO.\", \"Vessel_Name\", \"Year_Built\", \"Gross_Tonnage\", \"Deadweight_Tonnage\", \"Length\", \"Beam\", \"Capacity_(TEU)\", \"Forward_Bays\", \"Center_Bays\", \"Aft_Bays\"]\n",
    "data = pd.read_csv('containers.csv',names=cols)\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Explore the data**\n",
    "\n",
    "Our first step is to summarize the DataFrame by  computing aggregations. We can do this by using the info method in Pandas. We can see that all data is non-null as expected and we have 8 numeric values, one target, and one String."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()\n",
    "data.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding outliers and inconsistent data** \n",
    "\n",
    "For each of these features, comparing the max and 75% values, we can start to see a huge difference in the Beam (Width) feature. This confirms that there may be an error with some of the tuples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['IMO_NO.'].value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Duplicate Vessel Identification Number (IMO)**\n",
    "\n",
    "Now lets count the vessel identification number, which should be unique for the given dataset, however we can easily spot a duplicate IMO vessel. An online search shows that this vessel was renamed/purchased, we will leave in this duplicate vessel. IMO No. 9314947 in the dataset.\n",
    "\n",
    "Let us investigate further."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let‚Äôs have a quick look at the distribution of the Beam feature by plotting the histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for col in data.iloc[:,2:11]:\n",
    "data['Beam'].hist(figsize=(5, 3), bins=30, edgecolor=\"black\", )\n",
    "plt.subplots_adjust(hspace=0.7, wspace=0.4)\n",
    "plt.title('Beam (width distribution)')\n",
    "plt.xlabel('Beam (width)')\n",
    "plt.ylabel(\"Sum of Totals\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fix the outlier, incorrect data**\n",
    "\n",
    "Here we can see one ship has a length and width of 300x290 meters. I've never seen a almost square vessel before, probably doesn't go very fast!  The outlier is identified as MSC Albany with IMO 9619438. Correct beam should be 48meters. (https://www.vesselfinder.com/vessels/details/9619438) Since we have good reason to believe this is factually incorrect data it would be appropriate to correct the Beam to 48 meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the outlier as index 32, width cannot be the same as the length of the ship.\n",
    "\n",
    "print(data.loc[32])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_beam_MSC_Albany = 48\n",
    "edited_data = data.copy()\n",
    "edited_data.at[32,'Beam'] = corrected_beam_MSC_Albany\n",
    "edited_data.loc[32]\n",
    "edited_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* **Split the data (training & testing)**\n",
    "\n",
    "- 75% Training data (Default)\n",
    "- 25% Testing data (Default)\n",
    "  A high traininset set of 75% will prevent overfitting*\n",
    "  underfitting is too simple\n",
    "\n",
    "* Shuffle the data\n",
    "\n",
    "By default train_test_split method shuffle the Dataframe randomly prior to splitting, hence we do not need to shuffle beforehand. Shuffling the data ensures that there are no patterns or structure in the order of the data that could *bias the results* of the model. It also ensures that both the training and testing dataset contains a good generalization of the model and is representative of the overall distribution of the vessel data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = edited_data.copy() # Copy prevents mutation of the original dataset incase we need to revert changes.\n",
    "y = edited_data['Capacity_(TEU)'].copy() # Prevents mutation.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=0)\n",
    "X_Test_With_All_Columns = X_test.copy() # Keep a copy of the X_Test before dropping columns & Normalization below\n",
    "\n",
    "# Log the number of training and testing data, you can see 75% for training,a nd 25% for testing.\n",
    "print(X_train.shape, X_test.shape,y_train.shape,y_test.shape)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * Drop features that are not required to train the model, such as the target variable and the IMO_NO & Vessel_Name in order to lower dimension. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['IMO_NO.','Vessel_Name','Capacity_(TEU)']\n",
    "X_train.drop(columns=cols_to_drop, axis=1, inplace=True) #Dropped cols\n",
    "X_test.drop(columns=cols_to_drop, axis=1, inplace=True) #Dropped Cols\n",
    "\n",
    "print(len(X_train)) # 75% Training data\n",
    "print(len(X_test)) # 25% Testing data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalize using StandardScaler**\n",
    "\n",
    "Now let us normalize the data to ensure that the values share a common scale, this will reduce complexity and optimize the data for machine learning. In this case we will use the StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaled_X_Train = scaler.fit_transform(X_train)\n",
    "scaled_X_Test = scaler.fit_transform(X_test)\n",
    "print(scaled_X_Train) # Prints the scaled Training data\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our data is now prepared for Modeling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 1.2 REGRESSION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pipelines**\n",
    "\n",
    "We will be training our model on 3 regression algorithm's mentioned below. In order to efficiently load the models and evaluate each of them. We can use *make_pipeline from sklearn.pipeline*.\n",
    "\n",
    "- Random Forest (Decision Trees)\n",
    "- Multi Layer Perceptron  (MLP)\n",
    "- Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the required dependencies\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Set up pipelines for each algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Store all the pipeline inside a dictionary.\n",
    "pipelines = {\n",
    "    'Random_Forest': make_pipeline(RandomForestRegressor(random_state=0)),\n",
    "    'Multi_Layer_Percepton' : make_pipeline(MLPRegressor(random_state=0)),\n",
    "    'Support_Vector_Regression' : make_pipeline(SVR())\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the 3 algorithms contain tunable hyperparameters, instead of manually tuning parameter for our dataset, we can utilize sklearn GridSearchCV. \n",
    "\n",
    "GridSearchCV provides a exhaustive search *(2-10 mins depending on CPU power)* on our predefined parameters for each algorithm. This returns the best possible combination of hyperparameters for each of our 3 algorithms used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Set up a hyperparameter grid, the model will go through each of the parameters one by one in order to find the best convergence.\n",
    "\n",
    "hyper_param_grid = {\n",
    "    'Random_Forest': {\n",
    "        'randomforestregressor__n_estimators':[50,100,200]\n",
    "    },\n",
    "    'Multi_Layer_Percepton' : {\n",
    "        'mlpregressor__hidden_layer_sizes':[100],\n",
    "        'mlpregressor__solver':['adam','lbfgs'],\n",
    "        'mlpregressor__max_iter':[1000,10000,20000]\n",
    "    },\n",
    "    'Support_Vector_Regression': {\n",
    "        'svr__kernel':['rbf','sigmoid'],\n",
    "\n",
    "    }    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Grid Search CV\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.exceptions import NotFittedError #Suppress warnings from stdout\n",
    "import warnings #Import python warning package\n",
    "from sklearn.exceptions import ConvergenceWarning # Disable Convergence Warnings\n",
    "warnings.filterwarnings(action='ignore', category=ConvergenceWarning,)\n",
    "\n",
    "fit_model = {} #Dictionary that holds our models\n",
    "\n",
    "for algo,pipeline in pipelines.items():\n",
    "    try:\n",
    "        model = GridSearchCV(pipeline,hyper_param_grid[algo], cv=10, n_jobs=1)\n",
    "        print('Training started for',algo,'...')\n",
    "        model.fit(scaled_X_Train,y_train)\n",
    "        fit_model[algo] = model\n",
    "        print (algo, 'has been fitted! üëè')\n",
    "        print (\"========================================\")\n",
    "    except NotFittedError as e:\n",
    "        print (\"Error detected\")\n",
    "        print(repr(e))\n",
    "\n",
    "print(\"All Training has been completed!! üëèüëè\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TOP 10 CONTAINERS ORDERED BY PREDICTED CAPACITY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {}\n",
    "Top10 = X_Test_With_All_Columns.loc[:,cols_to_drop]\n",
    "for algo,pipeline in pipelines.items():\n",
    "   predictions[algo] = fit_model[algo].predict(scaled_X_Test)\n",
    "   Top10[algo] = predictions[algo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Top10.sort_values('Random_Forest', ascending=False).reset_index(drop=True).head(10))\n",
    "RandomForestSet = Top10.drop([\"Multi_Layer_Percepton\",\"Support_Vector_Regression\"],axis=1).sort_values('Random_Forest', ascending=False).reset_index(drop=True).head(10)\n",
    "MLPSet = Top10.drop([\"Random_Forest\",\"Support_Vector_Regression\"],axis=1).sort_values('Multi_Layer_Percepton', ascending=False).reset_index(drop=True).head(10)\n",
    "SVR = Top10.drop([\"Random_Forest\",\"Multi_Layer_Percepton\"],axis=1).sort_values('Support_Vector_Regression', ascending=False).reset_index(drop=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IMO_NO.</th>\n",
       "      <th>Vessel_Name</th>\n",
       "      <th>Capacity_(TEU)</th>\n",
       "      <th>Random_Forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9776418</td>\n",
       "      <td>CMA CGM ANTOINE DE SAINT EXUPERY</td>\n",
       "      <td>20776</td>\n",
       "      <td>23414.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9695121</td>\n",
       "      <td>CSCL GLOBE</td>\n",
       "      <td>19100</td>\n",
       "      <td>20288.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9454436</td>\n",
       "      <td>CMA CGM MARCO POLO</td>\n",
       "      <td>16022</td>\n",
       "      <td>18796.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9869186</td>\n",
       "      <td>HMM GARAM</td>\n",
       "      <td>16010</td>\n",
       "      <td>16867.355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9728942</td>\n",
       "      <td>TAURUS</td>\n",
       "      <td>14354</td>\n",
       "      <td>15654.370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9467263</td>\n",
       "      <td>CSCL JUPITER</td>\n",
       "      <td>14074</td>\n",
       "      <td>15246.165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9467392</td>\n",
       "      <td>MSC BERYL</td>\n",
       "      <td>12400</td>\n",
       "      <td>13974.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9612997</td>\n",
       "      <td>ANTWERPEN EXPRESS</td>\n",
       "      <td>13167</td>\n",
       "      <td>13962.580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9739680</td>\n",
       "      <td>MAERSK GENOA</td>\n",
       "      <td>10100</td>\n",
       "      <td>10180.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9685334</td>\n",
       "      <td>MOL BRILLIANCE</td>\n",
       "      <td>10100</td>\n",
       "      <td>10081.775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IMO_NO.                       Vessel_Name  Capacity_(TEU)  Random_Forest\n",
       "0  9776418  CMA CGM ANTOINE DE SAINT EXUPERY           20776      23414.075\n",
       "1  9695121                        CSCL GLOBE           19100      20288.460\n",
       "2  9454436                CMA CGM MARCO POLO           16022      18796.990\n",
       "3  9869186                         HMM GARAM           16010      16867.355\n",
       "4  9728942                            TAURUS           14354      15654.370\n",
       "5  9467263                      CSCL JUPITER           14074      15246.165\n",
       "6  9467392                         MSC BERYL           12400      13974.760\n",
       "7  9612997                 ANTWERPEN EXPRESS           13167      13962.580\n",
       "8  9739680                      MAERSK GENOA           10100      10180.660\n",
       "9  9685334                    MOL BRILLIANCE           10100      10081.775"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForestSet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use R2 SCORE AND MAE\n",
    "high r2 is better\n",
    "low mae is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IMO_NO.</th>\n",
       "      <th>Vessel_Name</th>\n",
       "      <th>Capacity_(TEU)</th>\n",
       "      <th>Multi_Layer_Percepton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9776418</td>\n",
       "      <td>CMA CGM ANTOINE DE SAINT EXUPERY</td>\n",
       "      <td>20776</td>\n",
       "      <td>24122.937263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9695121</td>\n",
       "      <td>CSCL GLOBE</td>\n",
       "      <td>19100</td>\n",
       "      <td>20258.303437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9869186</td>\n",
       "      <td>HMM GARAM</td>\n",
       "      <td>16010</td>\n",
       "      <td>19456.650494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9454436</td>\n",
       "      <td>CMA CGM MARCO POLO</td>\n",
       "      <td>16022</td>\n",
       "      <td>18437.310102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9728942</td>\n",
       "      <td>TAURUS</td>\n",
       "      <td>14354</td>\n",
       "      <td>16682.308123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9467263</td>\n",
       "      <td>CSCL JUPITER</td>\n",
       "      <td>14074</td>\n",
       "      <td>14674.559537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9612997</td>\n",
       "      <td>ANTWERPEN EXPRESS</td>\n",
       "      <td>13167</td>\n",
       "      <td>14037.431501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9739680</td>\n",
       "      <td>MAERSK GENOA</td>\n",
       "      <td>10100</td>\n",
       "      <td>13375.848180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9467392</td>\n",
       "      <td>MSC BERYL</td>\n",
       "      <td>12400</td>\n",
       "      <td>12903.598315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9685334</td>\n",
       "      <td>MOL BRILLIANCE</td>\n",
       "      <td>10100</td>\n",
       "      <td>12600.573498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IMO_NO.                       Vessel_Name  Capacity_(TEU)  \\\n",
       "0  9776418  CMA CGM ANTOINE DE SAINT EXUPERY           20776   \n",
       "1  9695121                        CSCL GLOBE           19100   \n",
       "2  9869186                         HMM GARAM           16010   \n",
       "3  9454436                CMA CGM MARCO POLO           16022   \n",
       "4  9728942                            TAURUS           14354   \n",
       "5  9467263                      CSCL JUPITER           14074   \n",
       "6  9612997                 ANTWERPEN EXPRESS           13167   \n",
       "7  9739680                      MAERSK GENOA           10100   \n",
       "8  9467392                         MSC BERYL           12400   \n",
       "9  9685334                    MOL BRILLIANCE           10100   \n",
       "\n",
       "   Multi_Layer_Percepton  \n",
       "0           24122.937263  \n",
       "1           20258.303437  \n",
       "2           19456.650494  \n",
       "3           18437.310102  \n",
       "4           16682.308123  \n",
       "5           14674.559537  \n",
       "6           14037.431501  \n",
       "7           13375.848180  \n",
       "8           12903.598315  \n",
       "9           12600.573498  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLPSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IMO_NO.</th>\n",
       "      <th>Vessel_Name</th>\n",
       "      <th>Capacity_(TEU)</th>\n",
       "      <th>Support_Vector_Regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9776418</td>\n",
       "      <td>CMA CGM ANTOINE DE SAINT EXUPERY</td>\n",
       "      <td>20776</td>\n",
       "      <td>8591.403943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9695121</td>\n",
       "      <td>CSCL GLOBE</td>\n",
       "      <td>19100</td>\n",
       "      <td>8586.345558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9869186</td>\n",
       "      <td>HMM GARAM</td>\n",
       "      <td>16010</td>\n",
       "      <td>8585.089410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9454436</td>\n",
       "      <td>CMA CGM MARCO POLO</td>\n",
       "      <td>16022</td>\n",
       "      <td>8583.338198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9728942</td>\n",
       "      <td>TAURUS</td>\n",
       "      <td>14354</td>\n",
       "      <td>8580.994141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9467263</td>\n",
       "      <td>CSCL JUPITER</td>\n",
       "      <td>14074</td>\n",
       "      <td>8576.421311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9612997</td>\n",
       "      <td>ANTWERPEN EXPRESS</td>\n",
       "      <td>13167</td>\n",
       "      <td>8574.979698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9467392</td>\n",
       "      <td>MSC BERYL</td>\n",
       "      <td>12400</td>\n",
       "      <td>8571.885834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9739680</td>\n",
       "      <td>MAERSK GENOA</td>\n",
       "      <td>10100</td>\n",
       "      <td>8554.684207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9685334</td>\n",
       "      <td>MOL BRILLIANCE</td>\n",
       "      <td>10100</td>\n",
       "      <td>8551.865549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IMO_NO.                       Vessel_Name  Capacity_(TEU)  \\\n",
       "0  9776418  CMA CGM ANTOINE DE SAINT EXUPERY           20776   \n",
       "1  9695121                        CSCL GLOBE           19100   \n",
       "2  9869186                         HMM GARAM           16010   \n",
       "3  9454436                CMA CGM MARCO POLO           16022   \n",
       "4  9728942                            TAURUS           14354   \n",
       "5  9467263                      CSCL JUPITER           14074   \n",
       "6  9612997                 ANTWERPEN EXPRESS           13167   \n",
       "7  9467392                         MSC BERYL           12400   \n",
       "8  9739680                      MAERSK GENOA           10100   \n",
       "9  9685334                    MOL BRILLIANCE           10100   \n",
       "\n",
       "   Support_Vector_Regression  \n",
       "0                8591.403943  \n",
       "1                8586.345558  \n",
       "2                8585.089410  \n",
       "3                8583.338198  \n",
       "4                8580.994141  \n",
       "5                8576.421311  \n",
       "6                8574.979698  \n",
       "7                8571.885834  \n",
       "8                8554.684207  \n",
       "9                8551.865549  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error,mean_squared_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for algo,model in fit_model.items():\n",
    "    y_prediction = model.predict(X_test_Dropped)\n",
    "    print(f'{algo}| R2 = {r2_score(y_test, y_prediction)} | MAE = {mean_absolute_error(y_test,y_prediction)} | MSE = {mean_squared_error(y_test,y_prediction)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test\n",
    "X_Test_Unscaled = pd.DataFrame(scaler.inverse_transform(X_test).astype(int))\n",
    "X_Test_Unscaled.columns = ['Year_Built','Gross_Tonnage','Deadweight_Tonnage','Length','Beam','Forward_Bays','Center_Bays','Aft_Bays']\n",
    "X_Test_Unscaled = pd.concat([X_Test_Unscaled,])\n",
    "# print('edidt date lengt ', len(edited_data))\n",
    "# addedBack = X_Test_Unscaled.join(edited_data.set_index(edited_data.index)[cols_to_drop]).reindex(columns=edited_data.columns)\n",
    "# print(addedBack)\n",
    "addedBack = pd.concat(X_edited_data.loc[X_Test_Unscaled.index, cols_to_drop],left_index=True,right_index=True)\n",
    "addedBack\n",
    "df_test_unnormalized = pd.concat([X_Test_Unscaled.reset_index(drop=True), edited_data.loc[X_test.index, ['A', 'C']].reset_index(drop=True), pd.DataFrame({'A_pred': y_pred_unnormalized})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
