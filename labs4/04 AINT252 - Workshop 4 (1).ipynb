{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Introduction\n",
    "This workshop builds on this week's lecture, which introduced the idea of _evolutionary computation_. In this session you will start to construct the building blocks required to optimise a problem using a hillclimber. You will work with a benchmark optimisation problem - the _OneMax_ problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OneMax\n",
    "The OneMax problem is a binary problem (its decision variables $x_d$ are either 1 or 0), and the objective function is as follows:\n",
    "$$ f(x) = \\sum^D_{d=1} x_d $$\n",
    "The problem can be optimised with any value of $D$ - the more decision variables you have, the more complex the optimisation problem. The problem is a maximisation function, and the maximum value is found when all $D$ decision variables is set to 1 (remember, that this is not information that the optimiser has!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "Implement a Python function called ``onemax`` that takes as an argument a sequence (e.g. a list or Numpy array) of 1s and 0s and returns the fitness result (i.e., the sum of the bits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onemax(x):\n",
    "    \"\"\"\n",
    "    The solution is a Numpy array called x.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "Write a second function that generates a random solution -- so a random sequence (list or Numpy array) of 1s and 0s. The ``numpy.random`` package will be helpful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_binary_solution(D):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try out the two functions.\n",
    "D = 10\n",
    "for i in range(5):\n",
    "    x = random_binary_solution(D)\n",
    "    y = onemax(x)\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "Implement a __bit flip__ mutation operator.\n",
    " 1. Pick a random decision variable.\n",
    " 1. If the decision variable is 0, change it to 1. Otherwise, if the decision variable is 1, change it to 0.\n",
    " 1. Return the mutated solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate(x):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "Write a function called ``evolve`` that performs a single generation of optimisation. Remember, given a starting solution and corresponding fitness values, a single generation should do the following:\n",
    " 1. __Mutate__ each of the current solution and evaluate the mutant according to the fitness function.\n",
    " 1. __Select__ the parent solution for the next generation (which solution -- parent or child -- has the highest fitness?).\n",
    " \n",
    "At the end of the ``evolve`` function you should return the new parent solution and its corresponding fitness value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evolve(parent, parent_fitness):\n",
    "    # Mutation & evaluation.\n",
    "    \n",
    "    # Selection.\n",
    "    \n",
    "    # Return the new parent solutions (and fitness values).\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6\n",
    "Using the ``evolve`` function, write a function that runs the optimisation process for a number of generations. The number of generations should be specified with the argument ``Ngens``. The number of decision variables should be specified with the argument ``D``. The final solution should be returned (along with its fitness). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimise(Ngens, D):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the optimiser."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
